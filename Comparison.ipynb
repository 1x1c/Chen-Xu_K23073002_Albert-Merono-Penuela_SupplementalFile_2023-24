{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7K9Kv_R6mTaB",
    "outputId": "7a7ee8c9-eb78-45a7-8c3f-0004026ac604"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 100it [00:35,  2.80it/s]\n",
      "<ipython-input-36-653e4307dc8b>:54: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  sampled_nodes = random.sample(G1.nodes(), sample_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nodes: 27883\n",
      "Total number of edges: 4841085\n",
      "Average degree (sampled): 341.47991391678624\n",
      "Average clustering coefficient (sampled): 0.8739072123657186\n",
      "Average diameter (sampled): 6\n",
      "Average path length (sampled): 2.2182680633654766\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the file path\n",
    "file_path = 'audio_editors.csv'\n",
    "\n",
    "# Initialize an empty graph\n",
    "G1 = nx.Graph()\n",
    "\n",
    "# Define a dictionary to map editor names to nodes in the graph\n",
    "editor_to_node = {}\n",
    "\n",
    "def get_or_create_node(editor):\n",
    "    if editor not in editor_to_node:\n",
    "        # Create a new node for each unique editor\n",
    "        node_id = len(editor_to_node)  # Use the current dictionary length as the node ID\n",
    "        editor_to_node[editor] = node_id\n",
    "        G1.add_node(node_id)  # Add node to the graph\n",
    "    return editor_to_node[editor]\n",
    "\n",
    "# Define a function to process edges\n",
    "def process_edges(df):\n",
    "    edges_to_add = []\n",
    "    for _, group in df.groupby('item'):\n",
    "        editors = group['editor'].dropna().unique()\n",
    "        if len(editors) > 1:\n",
    "            editor_nodes = [get_or_create_node(editor) for editor in editors]\n",
    "            editor_combinations = combinations(editor_nodes, 2)\n",
    "            for edge in editor_combinations:\n",
    "                if edge[0] is not None and edge[1] is not None:\n",
    "                    edges_to_add.append(edge)\n",
    "    return edges_to_add\n",
    "\n",
    "# Set chunk size\n",
    "chunksize = 10000\n",
    "\n",
    "# Read data, process in chunks\n",
    "for chunk in tqdm(pd.read_csv(file_path, dtype={'item': str, 'editor': str}, chunksize=chunksize), desc=\"Processing chunks\"):\n",
    "    chunk = chunk[chunk['editor'].notna()]  # Remove entries with no editor\n",
    "    chunk = chunk[chunk['editor'].str.strip() != '']  # Remove entries where editor is an empty string\n",
    "    edges = process_edges(chunk)\n",
    "    if edges:\n",
    "        G1.add_edges_from(edges)\n",
    "\n",
    "# Calculate network statistics\n",
    "number_of_nodes = G1.number_of_nodes()\n",
    "number_of_edges = G1.number_of_edges()\n",
    "\n",
    "# Sample nodes to estimate statistics\n",
    "sample_size = int(0.1 * number_of_nodes)  # For example, sample 10% of nodes\n",
    "sampled_nodes = random.sample(G1.nodes(), sample_size)\n",
    "\n",
    "# Calculate average degree (sampled)\n",
    "average_degree = sum(dict(G1.degree(sampled_nodes)).values()) / sample_size\n",
    "\n",
    "# Calculate average clustering coefficient (sampled)\n",
    "average_clustering_coefficient = nx.average_clustering(G1, nodes=sampled_nodes)\n",
    "\n",
    "# Create a sampled subgraph to calculate diameter and average path length\n",
    "sampled_subgraph = G1.subgraph(sampled_nodes)\n",
    "if nx.is_connected(sampled_subgraph):\n",
    "    average_diameter = nx.diameter(sampled_subgraph)\n",
    "    average_path_length = nx.average_shortest_path_length(sampled_subgraph)\n",
    "else:\n",
    "    # Handle the case of a disconnected subgraph\n",
    "    largest_cc = max(nx.connected_components(sampled_subgraph), key=len)\n",
    "    largest_subgraph = G1.subgraph(largest_cc)\n",
    "    average_diameter = nx.diameter(largest_subgraph)\n",
    "    average_path_length = nx.average_shortest_path_length(largest_subgraph)\n",
    "\n",
    "# Print overall results\n",
    "print(f\"Total number of nodes: {number_of_nodes}\")\n",
    "print(f\"Total number of edges: {number_of_edges}\")\n",
    "print(f\"Average degree (sampled): {average_degree}\")\n",
    "print(f\"Average clustering coefficient (sampled): {average_clustering_coefficient}\")\n",
    "print(f\"Average diameter (sampled): {average_diameter}\")\n",
    "print(f\"Average path length (sampled): {average_path_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vdC5f9wNjjm4",
    "outputId": "7f1fd634-50d2-4cb6-d5d2-0c1eead56c0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of communities detected: 11\n",
      "Modularity of the partition: 0.2366\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import community.community_louvain as cl\n",
    "\n",
    "# Use the Louvain algorithm to find the optimal community division of the network\n",
    "partition = cl.best_partition(G1)\n",
    "\n",
    "# Calculate the number of communities\n",
    "number_of_communities = len(set(partition.values()))\n",
    "\n",
    "# Calculate modularity\n",
    "modularity = cl.modularity(partition, G1)\n",
    "\n",
    "# Output basic information about the communities\n",
    "print(f\"Number of communities detected: {number_of_communities}\")\n",
    "print(f\"Modularity of the partition: {modularity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HBi1p4_kjuK1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VkMuYvlnjuiH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1_lQOvpycfcl",
    "outputId": "b0b6fe36-e6d4-409e-b7d7-ba94f6a66002"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 197it [01:42,  1.92it/s]\n",
      "<ipython-input-38-07a6995cdc3e>:54: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  sampled_nodes = random.sample(G2.nodes(), sample_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nodes: 68741\n",
      "Total number of edges: 14282127\n",
      "Average degree : 427.2430858806405\n",
      "Average clustering coefficient : 0.8909310711687697\n",
      "Average diameter : 4\n",
      "Average path length : 2.253940152365607\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the file path\n",
    "file_path = 'video_editors.csv'\n",
    "\n",
    "# Initialize an empty network graph\n",
    "G2 = nx.Graph()\n",
    "\n",
    "# Define a dictionary to map editor names to graph nodes\n",
    "editor_to_node = {}\n",
    "\n",
    "def get_or_create_node(editor):\n",
    "    if editor not in editor_to_node:\n",
    "        # Create a new node for each unique editor\n",
    "        node_id = len(editor_to_node)  # Use the current dictionary length as the node ID\n",
    "        editor_to_node[editor] = node_id\n",
    "        G2.add_node(node_id)  # Add the node to the graph\n",
    "    return editor_to_node[editor]\n",
    "\n",
    "# Define a function to process edges\n",
    "def process_edges(df):\n",
    "    edges_to_add = []\n",
    "    for _, group in df.groupby('item'):\n",
    "        editors = group['editor'].dropna().unique()\n",
    "        if len(editors) > 1:\n",
    "            editor_nodes = [get_or_create_node(editor) for editor in editors]\n",
    "            editor_combinations = combinations(editor_nodes, 2)\n",
    "            for edge in editor_combinations:\n",
    "                if edge[0] is not None and edge[1] is not None:\n",
    "                    edges_to_add.append(edge)\n",
    "    return edges_to_add\n",
    "\n",
    "# Set the chunk size\n",
    "chunksize = 10000\n",
    "\n",
    "# Read and process data in chunks\n",
    "for chunk in tqdm(pd.read_csv(file_path, dtype={'item': str, 'editor': str}, chunksize=chunksize), desc=\"Processing chunks\"):\n",
    "    chunk = chunk[chunk['editor'].notna()]  # Remove empty editors\n",
    "    chunk = chunk[chunk['editor'].str.strip() != '']  # Remove blank string editors\n",
    "    edges = process_edges(chunk)\n",
    "    if edges:\n",
    "        G2.add_edges_from(edges)\n",
    "\n",
    "# Calculate network statistics\n",
    "number_of_nodes = G2.number_of_nodes()\n",
    "number_of_edges = G2.number_of_edges()\n",
    "\n",
    "# Sample nodes to estimate statistics\n",
    "sample_size = int(0.02 * number_of_nodes)  # For example, take 2% of nodes for sampling\n",
    "sampled_nodes = random.sample(G2.nodes(), sample_size)\n",
    "\n",
    "# Calculate average degree (sampled)\n",
    "average_degree = sum(dict(G2.degree(sampled_nodes)).values()) / sample_size\n",
    "\n",
    "# Calculate average clustering coefficient (sampled)\n",
    "average_clustering_coefficient = nx.average_clustering(G2, nodes=sampled_nodes)\n",
    "\n",
    "# Create a sampled subgraph for calculating diameter and average path length\n",
    "sampled_subgraph = G2.subgraph(sampled_nodes)\n",
    "if nx.is_connected(sampled_subgraph):\n",
    "    average_diameter = nx.diameter(sampled_subgraph)\n",
    "    average_path_length = nx.average_shortest_path_length(sampled_subgraph)\n",
    "else:\n",
    "    # Handle the case of a non-connected subgraph\n",
    "    largest_cc = max(nx.connected_components(sampled_subgraph), key=len)\n",
    "    largest_subgraph = G2.subgraph(largest_cc)\n",
    "    average_diameter = nx.diameter(largest_subgraph)\n",
    "    average_path_length = nx.average_shortest_path_length(largest_subgraph)\n",
    "\n",
    "# Print overall results\n",
    "print(f\"Total number of nodes: {number_of_nodes}\")\n",
    "print(f\"Total number of edges: {number_of_edges}\")\n",
    "print(f\"Average degree : {average_degree}\")\n",
    "print(f\"Average clustering coefficient : {average_clustering_coefficient}\")\n",
    "print(f\"Average diameter : {average_diameter}\")\n",
    "print(f\"Average path length : {average_path_length}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PST054ZThgLB",
    "outputId": "de8f87ee-4053-4e3b-c45a-98e85432143d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of communities detected: 14\n",
      "Modularity of the partition: 0.2041\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import community.community_louvain as cl\n",
    "\n",
    "# Use the Louvain algorithm to find the optimal community partition of the network\n",
    "partition = cl.best_partition(G2)\n",
    "\n",
    "# Calculate the number of communities\n",
    "number_of_communities = len(set(partition.values()))\n",
    "\n",
    "# Calculate modularity\n",
    "modularity = cl.modularity(partition, G2)\n",
    "\n",
    "# Output basic information about the communities\n",
    "print(f\"Number of communities detected: {number_of_communities}\")\n",
    "print(f\"Modularity of the partition: {modularity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rUW-eu0jkUOi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zASCg3k_kUMc",
    "outputId": "2465a50b-cfd0-4fdc-e176-3d0cd611930a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 744it [05:43,  2.17it/s]\n",
      "<ipython-input-40-11c3a784f28f>:54: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  sampled_nodes = random.sample(G3.nodes(), sample_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nodes: 125705\n",
      "Total number of edges: 26219143\n",
      "Average degree: 408.2110845929462\n",
      "Average clustering coefficient: 0.9158438432363202\n",
      "Average diameter: 5\n",
      "Average path length: 2.415933978817237\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the file path\n",
    "file_path = 'image_editors.csv'\n",
    "\n",
    "# Initialize an empty network graph\n",
    "G3 = nx.Graph()\n",
    "\n",
    "# Define a dictionary to map editor names to graph nodes\n",
    "editor_to_node = {}\n",
    "\n",
    "def get_or_create_node(editor):\n",
    "    if editor not in editor_to_node:\n",
    "        # Create a new node for each unique editor\n",
    "        node_id = len(editor_to_node)  # Use the current dictionary length as the node ID\n",
    "        editor_to_node[editor] = node_id\n",
    "        G3.add_node(node_id)  # Add the node to the graph\n",
    "    return editor_to_node[editor]\n",
    "\n",
    "# Define a function to process edges\n",
    "def process_edges(df):\n",
    "    edges_to_add = []\n",
    "    for _, group in df.groupby('item'):\n",
    "        editors = group['editor'].dropna().unique()\n",
    "        if len(editors) > 1:\n",
    "            editor_nodes = [get_or_create_node(editor) for editor in editors]\n",
    "            editor_combinations = combinations(editor_nodes, 2)\n",
    "            for edge in editor_combinations:\n",
    "                if edge[0] is not None and edge[1] is not None:\n",
    "                    edges_to_add.append(edge)\n",
    "    return edges_to_add\n",
    "\n",
    "# Set the chunk size\n",
    "chunksize = 10000\n",
    "\n",
    "# Read and process data in chunks\n",
    "for chunk in tqdm(pd.read_csv(file_path, dtype={'item': str, 'editor': str}, chunksize=chunksize), desc=\"Processing chunks\"):\n",
    "    chunk = chunk[chunk['editor'].notna()]  # Remove empty editors\n",
    "    chunk = chunk[chunk['editor'].str.strip() != '']  # Remove blank string editors\n",
    "    edges = process_edges(chunk)\n",
    "    if edges:\n",
    "        G3.add_edges_from(edges)\n",
    "\n",
    "# Calculate network statistics\n",
    "number_of_nodes = G3.number_of_nodes()\n",
    "number_of_edges = G3.number_of_edges()\n",
    "\n",
    "# Sample nodes to estimate statistics\n",
    "sample_size = int(0.03 * number_of_nodes)  # For example, take 2% of nodes for sampling\n",
    "sampled_nodes = random.sample(G3.nodes(), sample_size)\n",
    "\n",
    "# Calculate average degree (sampled)\n",
    "average_degree = sum(dict(G3.degree(sampled_nodes)).values()) / sample_size\n",
    "\n",
    "# Calculate average clustering coefficient (sampled)\n",
    "average_clustering_coefficient = nx.average_clustering(G3, nodes=sampled_nodes)\n",
    "\n",
    "# Create a sampled subgraph for calculating diameter and average path length\n",
    "sampled_subgraph = G3.subgraph(sampled_nodes)\n",
    "if nx.is_connected(sampled_subgraph):\n",
    "    average_diameter = nx.diameter(sampled_subgraph)\n",
    "    average_path_length = nx.average_shortest_path_length(sampled_subgraph)\n",
    "else:\n",
    "    # Handle the case of a non-connected subgraph\n",
    "    largest_cc = max(nx.connected_components(sampled_subgraph), key=len)\n",
    "    largest_subgraph = G3.subgraph(largest_cc)\n",
    "    average_diameter = nx.diameter(largest_subgraph)\n",
    "    average_path_length = nx.average_shortest_path_length(largest_subgraph)\n",
    "\n",
    "# Print overall results\n",
    "print(f\"Total number of nodes: {number_of_nodes}\")\n",
    "print(f\"Total number of edges: {number_of_edges}\")\n",
    "print(f\"Average degree: {average_degree}\")\n",
    "print(f\"Average clustering coefficient: {average_clustering_coefficient}\")\n",
    "print(f\"Average diameter: {average_diameter}\")\n",
    "print(f\"Average path length: {average_path_length}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QwhuEnAVkUKS",
    "outputId": "6e62fdbc-bde2-4897-8253-3b8df7a68f8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of communities detected: 17\n",
      "Modularity of the partition: 0.2041\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import community.community_louvain as cl\n",
    "\n",
    "# Use the Louvain algorithm to find the optimal community partition of the network\n",
    "partition = cl.best_partition(G3)\n",
    "\n",
    "# Calculate the number of communities\n",
    "number_of_communities = len(set(partition.values()))\n",
    "\n",
    "# Calculate modularity\n",
    "modularity = cl.modularity(partition, G3)\n",
    "\n",
    "# Output basic information about the communities\n",
    "print(f\"Number of communities detected: {number_of_communities}\")\n",
    "print(f\"Modularity of the partition: {modularity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R20Z3gSjkUHK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uysmhu2GkUBM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pXNP8pYJZ1NQ",
    "outputId": "b5af8076-bcad-4fa5-b104-92d28e3ec5a4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-6415ef168ac1>:17: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  sampled_nodes_r1 = random.sample(R1.nodes(), sample_size_r1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nodes (R1): 27883\n",
      "Total number of edges (R1): 3885287\n",
      "Average degree : 278.8629842180775\n",
      "Average clustering coefficient : 0.009994550133255039\n",
      "Average diameter : 4\n",
      "Average path length : 2.7417619414590906\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "\n",
    "# Define the number of nodes and the connection probability\n",
    "num_nodes = 27883\n",
    "connection_prob = 0.01\n",
    "\n",
    "# Generate a random network using NetworkX and rename it to R1\n",
    "R1 = nx.erdos_renyi_graph(n=num_nodes, p=connection_prob)\n",
    "\n",
    "# Calculate network statistics\n",
    "number_of_nodes_r1 = R1.number_of_nodes()\n",
    "number_of_edges_r1 = R1.number_of_edges()\n",
    "\n",
    "# Sample nodes to estimate statistics\n",
    "sample_size_r1 = int(0.1 * number_of_nodes_r1)  # For example, sample 10% of nodes\n",
    "sampled_nodes_r1 = random.sample(R1.nodes(), sample_size_r1)\n",
    "\n",
    "# Calculate average degree (sampled)\n",
    "average_degree_r1 = sum(dict(R1.degree(sampled_nodes_r1)).values()) / sample_size_r1\n",
    "\n",
    "# Calculate average clustering coefficient (sampled)\n",
    "average_clustering_coefficient_r1 = nx.average_clustering(R1, nodes=sampled_nodes_r1)\n",
    "\n",
    "# Create a sampled subgraph to calculate diameter and average path length\n",
    "sampled_subgraph_r1 = R1.subgraph(sampled_nodes_r1)\n",
    "if nx.is_connected(sampled_subgraph_r1):\n",
    "    average_diameter_r1 = nx.diameter(sampled_subgraph_r1)\n",
    "    average_path_length_r1 = nx.average_shortest_path_length(sampled_subgraph_r1)\n",
    "else:\n",
    "    # Handle the case of a disconnected subgraph\n",
    "    largest_cc_r1 = max(nx.connected_components(sampled_subgraph_r1), key=len)\n",
    "    largest_subgraph_r1 = R1.subgraph(largest_cc_r1)\n",
    "    average_diameter_r1 = nx.diameter(largest_subgraph_r1)\n",
    "    average_path_length_r1 = nx.average_shortest_path_length(largest_subgraph_r1)\n",
    "\n",
    "# Print overall results\n",
    "print(f\"Total number of nodes (R1): {number_of_nodes_r1}\")\n",
    "print(f\"Total number of edges (R1): {number_of_edges_r1}\")\n",
    "print(f\"Average degree : {average_degree_r1}\")\n",
    "print(f\"Average clustering coefficient : {average_clustering_coefficient_r1}\")\n",
    "print(f\"Average diameter : {average_diameter_r1}\")\n",
    "print(f\"Average path length : {average_path_length_r1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PipDRTmYaJE1",
    "outputId": "95562aa5-a4fb-48de-db67-1b2d42e92077"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of communities detected: 7\n",
      "Modularity of the partition: 0.0527\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import community.community_louvain as cl\n",
    "\n",
    "# Use the Louvain algorithm to find the optimal community partition of the network\n",
    "partition = cl.best_partition(R1)\n",
    "\n",
    "# Calculate the number of communities\n",
    "number_of_communities = len(set(partition.values()))\n",
    "\n",
    "# Calculate modularity\n",
    "modularity = cl.modularity(partition, R1)\n",
    "\n",
    "# Output basic information about the communities\n",
    "print(f\"Number of communities detected: {number_of_communities}\")\n",
    "print(f\"Modularity of the partition: {modularity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lQDxoJkLhSe1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1q8lXtNYhSsS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I1X5ruNdhscl",
    "outputId": "d311d58a-1f63-4a15-fb21-5806d409ec31"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-97e08a484bb5>:17: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  sampled_nodes_r2 = random.sample(R2.nodes(), sample_size_r2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nodes (R2): 68741\n",
      "Total number of edges (R2): 23623394\n",
      "Average degree : 686.8850630455868\n",
      "Average clustering coefficient : 0.010001502686752659\n",
      "Average diameter : 4\n",
      "Average path length : 2.8185892829326304\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "\n",
    "# Define the number of nodes and the connection probability\n",
    "num_nodes = 68741\n",
    "connection_prob = 0.01\n",
    "\n",
    "# Generate a random network using NetworkX and rename it to R2\n",
    "R2 = nx.erdos_renyi_graph(n=num_nodes, p=connection_prob)\n",
    "\n",
    "# Calculate network statistics\n",
    "number_of_nodes_r2 = R2.number_of_nodes()\n",
    "number_of_edges_r2 = R2.number_of_edges()\n",
    "\n",
    "# Sample nodes to estimate statistics\n",
    "sample_size_r2 = int(0.03 * number_of_nodes_r2)  # For example, sample 3% of nodes\n",
    "sampled_nodes_r2 = random.sample(R2.nodes(), sample_size_r2)\n",
    "\n",
    "# Calculate average degree (sampled)\n",
    "average_degree_r2 = sum(dict(R2.degree(sampled_nodes_r2)).values()) / sample_size_r2\n",
    "\n",
    "# Calculate average clustering coefficient (sampled)\n",
    "average_clustering_coefficient_r2 = nx.average_clustering(R2, nodes=sampled_nodes_r2)\n",
    "\n",
    "# Create a sampled subgraph to calculate diameter and average path length\n",
    "sampled_subgraph_r2 = R2.subgraph(sampled_nodes_r2)\n",
    "if nx.is_connected(sampled_subgraph_r2):\n",
    "    average_diameter_r2 = nx.diameter(sampled_subgraph_r2)\n",
    "    average_path_length_r2 = nx.average_shortest_path_length(sampled_subgraph_r2)\n",
    "else:\n",
    "    # Handle the case of a disconnected subgraph\n",
    "    largest_cc_r2 = max(nx.connected_components(sampled_subgraph_r2), key=len)\n",
    "    largest_subgraph_r2 = R2.subgraph(largest_cc_r2)\n",
    "    average_diameter_r2 = nx.diameter(largest_subgraph_r2)\n",
    "    average_path_length_r2 = nx.average_shortest_path_length(largest_subgraph_r2)\n",
    "\n",
    "# Print overall results\n",
    "print(f\"Total number of nodes (R2): {number_of_nodes_r2}\")\n",
    "print(f\"Total number of edges (R2): {number_of_edges_r2}\")\n",
    "print(f\"Average degree: {average_degree_r2}\")\n",
    "print(f\"Average clustering coefficient: {average_clustering_coefficient_r2}\")\n",
    "print(f\"Average diameter: {average_diameter_r2}\")\n",
    "print(f\"Average path length: {average_path_length_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1QpjI3rh3vV",
    "outputId": "9ec1d7f3-053e-4b0a-e4cf-b4bc90f3fcb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of communities detected: 8\n",
      "Modularity of the partition: 0.0326\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import community.community_louvain as cl\n",
    "\n",
    "# Use the Louvain algorithm to find the optimal community partition of the network\n",
    "partition = cl.best_partition(R2)\n",
    "\n",
    "# Calculate the number of communities\n",
    "number_of_communities = len(set(partition.values()))\n",
    "\n",
    "# Calculate modularity\n",
    "modularity = cl.modularity(partition, R2)\n",
    "\n",
    "# Output basic information about the communities\n",
    "print(f\"Number of communities detected: {number_of_communities}\")\n",
    "print(f\"Modularity of the partition: {modularity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aEZhuQUsiEXC",
    "outputId": "915337c0-d477-4237-a5e5-a5f2b35eb968"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nodes (R3): 125705\n",
      "Total number of edges (R3): 78989330\n",
      "Average degree : 1256.0373906125697\n",
      "Average clustering coefficient : 0.009998207635059845\n",
      "Average diameter : 4\n",
      "Average path length : 2.7698902857092205\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "\n",
    "# Define the number of nodes and the connection probability\n",
    "num_nodes = 125705\n",
    "connection_prob = 0.01\n",
    "\n",
    "# Generate a random network using NetworkX and rename it to R3\n",
    "R3 = nx.erdos_renyi_graph(n=num_nodes, p=connection_prob)\n",
    "\n",
    "# Calculate network statistics\n",
    "number_of_nodes_r3 = R3.number_of_nodes()\n",
    "number_of_edges_r3 = R3.number_of_edges()\n",
    "\n",
    "# Sample nodes to estimate statistics\n",
    "sample_size_r3 = int(0.02 * number_of_nodes_r3)  # For example, sample 2% of nodes\n",
    "sampled_nodes_r3 = random.sample(list(R3.nodes()), sample_size_r3)\n",
    "\n",
    "# Calculate average degree (sampled)\n",
    "average_degree_r3 = sum(dict(R3.degree(sampled_nodes_r3)).values()) / sample_size_r3\n",
    "\n",
    "# Calculate average clustering coefficient (sampled)\n",
    "average_clustering_coefficient_r3 = nx.average_clustering(R3, nodes=sampled_nodes_r3)\n",
    "\n",
    "# Create a sampled subgraph to calculate diameter and average path length\n",
    "sampled_subgraph_r3 = R3.subgraph(sampled_nodes_r3)\n",
    "if nx.is_connected(sampled_subgraph_r3):\n",
    "    average_diameter_r3 = nx.diameter(sampled_subgraph_r3)\n",
    "    average_path_length_r3 = nx.average_shortest_path_length(sampled_subgraph_r3)\n",
    "else:\n",
    "    # Handle the case of a disconnected subgraph\n",
    "    largest_cc_r3 = max(nx.connected_components(sampled_subgraph_r3), key=len)\n",
    "    largest_subgraph_r3 = R3.subgraph(largest_cc_r3)\n",
    "    average_diameter_r3 = nx.diameter(largest_subgraph_r3)\n",
    "    average_path_length_r3 = nx.average_shortest_path_length(largest_subgraph_r3)\n",
    "\n",
    "# Print overall results\n",
    "print(f\"Total number of nodes (R3): {number_of_nodes_r3}\")\n",
    "print(f\"Total number of edges (R3): {number_of_edges_r3}\")\n",
    "print(f\"Average degree: {average_degree_r3}\")\n",
    "print(f\"Average clustering coefficient: {average_clustering_coefficient_r3}\")\n",
    "print(f\"Average diameter: {average_diameter_r3}\")\n",
    "print(f\"Average path length: {average_path_length_r3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HOFB86trij0L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of communities detected: 7\n",
      "Modularity of the partition: 0.0245\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import community.community_louvain as cl\n",
    "\n",
    "# Use the Louvain algorithm to find the optimal community partition of the network\n",
    "partition = cl.best_partition(R3)\n",
    "\n",
    "# Calculate the number of communities\n",
    "number_of_communities = len(set(partition.values()))\n",
    "\n",
    "# Calculate modularity\n",
    "modularity = cl.modularity(partition, R3)\n",
    "\n",
    "# Output basic information about the communities\n",
    "print(f\"Number of communities detected: {number_of_communities}\")\n",
    "print(f\"Modularity of the partition: {modularity:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
